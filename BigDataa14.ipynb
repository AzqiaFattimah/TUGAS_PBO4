{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2a030e3",
      "metadata": {
        "id": "e2a030e3"
      },
      "source": [
        "# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099562db",
      "metadata": {
        "id": "099562db"
      },
      "source": [
        "## Objectives:\n",
        "- Understand and implement advanced machine learning tasks using Spark MLlib.\n",
        "- Build and evaluate models using real-world datasets.\n",
        "- Explore techniques like feature engineering and hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77df771a",
      "metadata": {
        "id": "77df771a"
      },
      "source": [
        "## Introduction to Spark MLlib\n",
        "Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJBeDQLNwfjp",
        "outputId": "9faf57a9-f819-4f7a-954b-f114f62a7fc5"
      },
      "id": "aJBeDQLNwfjp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ae225b",
      "metadata": {
        "id": "d9ae225b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78c81b2-c472-40b8-bc38-2f4adf8e5944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b266267",
      "metadata": {
        "id": "0b266267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3c31e4-934a-44d4-ea52-5dbbf3830846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionExample\").getOrCreate()\n",
        "\n",
        "# Example dataset\n",
        "data = [\n",
        "    (1, Vectors.dense([2.0, 3.0]), 0),\n",
        "    (2, Vectors.dense([1.0, 5.0]), 1),\n",
        "    (3, Vectors.dense([2.5, 4.5]), 1),\n",
        "    (4, Vectors.dense([3.0, 6.0]), 0)\n",
        "]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n",
        "model = lr.fit(df)\n",
        "\n",
        "# Display coefficients and summary\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9066e04",
      "metadata": {
        "id": "b9066e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b78d3e6-77c8-4303-f586-9c57c7c3a426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([12.5, 12.5]), array([3., 3.])]\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"KMeansClusteringExample\").getOrCreate()\n",
        "\n",
        "# Example dataset with DenseVector\n",
        "data = [\n",
        "    (1, Vectors.dense([1.0, 1.0])),\n",
        "    (2, Vectors.dense([5.0, 5.0])),\n",
        "    (3, Vectors.dense([10.0, 10.0])),\n",
        "    (4, Vectors.dense([15.0, 15.0]))\n",
        "]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='Features', k=2)\n",
        "model = kmeans.fit(df)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60a8d7e",
      "metadata": {
        "id": "a60a8d7e"
      },
      "source": [
        "## Homework\n",
        "- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n",
        "- Build a classification model using Spark MLlib and evaluate its performance.\n",
        "- Explore hyperparameter tuning using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Diabetes Dataset\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "data = spark.read.csv(\"diabetes_dataset_cleaned.csv\", header=True, inferSchema=True)\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEXXWZoPzA99",
        "outputId": "1e2e3b87-286f-428d-da0b-fc6cf1d96afa"
      },
      "id": "UEXXWZoPzA99",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+----+--------+--------------------+----------+--------------+-------------+----------+------------+-------------+---------------+-----+-----------+-------------------+--------+----------+-------------------+----------------------+------------------------------+\n",
            "|year|gender| age|location|race:AfricanAmerican|race:Asian|race:Caucasian|race:Hispanic|race:Other|hypertension|heart_disease|smoking_history|  bmi|hbA1c_level|blood_glucose_level|diabetes|Is Outlier|     Normalized bmi|Normalized hbA1c_level|Normalized blood_glucose_level|\n",
            "+----+------+----+--------+--------------------+----------+--------------+-------------+----------+------------+-------------+---------------+-----+-----------+-------------------+--------+----------+-------------------+----------------------+------------------------------+\n",
            "|2020|Female|32.0| Alabama|                   0|         0|             0|            0|         1|           0|            0|          never|27.32|        5.0|                100|       0|     false| 0.5300546448087432|    0.3191489361702129|                         0.125|\n",
            "|2015|Female|29.0| Alabama|                   0|         1|             0|            0|         0|           0|            0|          never|19.95|        5.0|                 90|       0|     false|0.22026061370323657|    0.3191489361702129|                        0.0625|\n",
            "|2015|  Male|18.0| Alabama|                   0|         0|             0|            0|         1|           0|            0|          never|23.76|        4.8|                160|       0|     false| 0.3804119377889871|   0.27659574468085113|                           0.5|\n",
            "|2015|  Male|41.0| Alabama|                   0|         0|             1|            0|         0|           0|            0|          never|27.32|        4.0|                159|       0|     false| 0.5300546448087432|    0.1063829787234043|                       0.49375|\n",
            "|2016|Female|52.0| Alabama|                   1|         0|             0|            0|         0|           0|            0|          never|23.75|        6.5|                 90|       0|     false| 0.3799915931063472|    0.6382978723404256|                        0.0625|\n",
            "+----+------+----+--------+--------------------+----------+--------------+-------------+----------+------------+-------------+---------------+-----+-----------+-------------------+--------+----------+-------------------+----------------------+------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Membuat SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Diabetes Dataset Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Memuat dataset dari CSV\n",
        "dataset = spark.read.csv(\"diabetes_dataset_cleaned.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Menampilkan 5 baris pertama untuk memverifikasi data\n",
        "dataset.show(5)\n",
        "\n",
        "# Menghapus baris yang merupakan outlier\n",
        "dataset = dataset.filter(dataset['Is Outlier'] == False)\n",
        "\n",
        "# Mengonversi kolom 'Is Outlier' dari Boolean ke Integer\n",
        "dataset = dataset.withColumn(\"Is Outlier\", dataset[\"Is Outlier\"].cast(\"integer\"))\n",
        "\n",
        "# Mengonversi kolom 'smoking_history' menjadi numerik dengan StringIndexer\n",
        "# Kita akan memberi nilai numerik untuk kategori dalam kolom 'smoking_history'\n",
        "smoking_indexer = StringIndexer(inputCol=\"smoking_history\", outputCol=\"smoking_history_indexed\")\n",
        "\n",
        "# Menyiapkan fitur untuk model klasifikasi (kecuali 'year' dan 'diabetes' sebagai label)\n",
        "feature_columns = [\n",
        "    'age', 'race:AfricanAmerican', 'race:Asian', 'race:Caucasian', 'race:Hispanic',\n",
        "    'race:Other', 'hypertension', 'heart_disease', 'bmi',\n",
        "    'hbA1c_level', 'blood_glucose_level', 'smoking_history_indexed'\n",
        "]\n",
        "\n",
        "# Menyiapkan label untuk model (yaitu 'Is Outlier')\n",
        "label_indexer = StringIndexer(inputCol=\"Is Outlier\", outputCol=\"label\")\n",
        "\n",
        "# Menyiapkan fitur menggunakan VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
        "\n",
        "# Membangun pipeline\n",
        "pipeline = Pipeline(stages=[smoking_indexer, label_indexer, assembler])\n",
        "\n",
        "# Melakukan transformasi data menggunakan pipeline\n",
        "model_data = pipeline.fit(dataset).transform(dataset)\n",
        "\n",
        "# Menampilkan fitur dan label yang sudah diproses\n",
        "model_data.select(\"features\", \"label\").show(5, truncate=False)\n",
        "\n",
        "# Menyimpan data yang telah diproses jika diperlukan\n",
        "# model_data.write.csv(\"processed_diabetes_data.csv\", header=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4-v6Qz01_Da",
        "outputId": "186c103d-8cc2-460d-b0cc-27bc3e0a39ed"
      },
      "id": "Q4-v6Qz01_Da",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+----+--------+--------------------+----------+--------------+-------------+----------+------------+-------------+---------------+-----+-----------+-------------------+--------+----------+-------------------+----------------------+------------------------------+\n",
            "|year|gender| age|location|race:AfricanAmerican|race:Asian|race:Caucasian|race:Hispanic|race:Other|hypertension|heart_disease|smoking_history|  bmi|hbA1c_level|blood_glucose_level|diabetes|Is Outlier|     Normalized bmi|Normalized hbA1c_level|Normalized blood_glucose_level|\n",
            "+----+------+----+--------+--------------------+----------+--------------+-------------+----------+------------+-------------+---------------+-----+-----------+-------------------+--------+----------+-------------------+----------------------+------------------------------+\n",
            "|2020|Female|32.0| Alabama|                   0|         0|             0|            0|         1|           0|            0|          never|27.32|        5.0|                100|       0|     false| 0.5300546448087432|    0.3191489361702129|                         0.125|\n",
            "|2015|Female|29.0| Alabama|                   0|         1|             0|            0|         0|           0|            0|          never|19.95|        5.0|                 90|       0|     false|0.22026061370323657|    0.3191489361702129|                        0.0625|\n",
            "|2015|  Male|18.0| Alabama|                   0|         0|             0|            0|         1|           0|            0|          never|23.76|        4.8|                160|       0|     false| 0.3804119377889871|   0.27659574468085113|                           0.5|\n",
            "|2015|  Male|41.0| Alabama|                   0|         0|             1|            0|         0|           0|            0|          never|27.32|        4.0|                159|       0|     false| 0.5300546448087432|    0.1063829787234043|                       0.49375|\n",
            "|2016|Female|52.0| Alabama|                   1|         0|             0|            0|         0|           0|            0|          never|23.75|        6.5|                 90|       0|     false| 0.3799915931063472|    0.6382978723404256|                        0.0625|\n",
            "+----+------+----+--------+--------------------+----------+--------------+-------------+----------+------------+-------------+---------------+-----+-----------+-------------------+--------+----------+-------------------+----------------------+------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+---------------------------------------------------+-----+\n",
            "|features                                           |label|\n",
            "+---------------------------------------------------+-----+\n",
            "|(12,[0,5,8,9,10,11],[32.0,1.0,27.32,5.0,100.0,1.0])|0.0  |\n",
            "|(12,[0,2,8,9,10,11],[29.0,1.0,19.95,5.0,90.0,1.0]) |0.0  |\n",
            "|(12,[0,5,8,9,10,11],[18.0,1.0,23.76,4.8,160.0,1.0])|0.0  |\n",
            "|(12,[0,3,8,9,10,11],[41.0,1.0,27.32,4.0,159.0,1.0])|0.0  |\n",
            "|(12,[0,1,8,9,10,11],[52.0,1.0,23.75,6.5,90.0,1.0]) |0.0  |\n",
            "+---------------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "train_data, test_data = model_data.randomSplit([0.8, 0.2], seed=1234)\n",
        "dt_classifier = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
        "dt_model = dt_classifier.fit(train_data)\n",
        "\n",
        "# Melakukan prediksi\n",
        "predictions = dt_model.transform(test_data)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "UMC4yIfqdnqr"
      },
      "id": "UMC4yIfqdnqr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Membangun grid untuk hyperparameter tuning\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(dt_classifier.maxDepth, [2, 5, 10]) \\\n",
        "    .addGrid(dt_classifier.minInstancesPerNode, [1, 2, 5]) \\\n",
        "    .build()\n",
        "\n",
        "# CrossValidator\n",
        "crossval = CrossValidator(estimator=dt_classifier,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)\n",
        "\n",
        "cv_model = crossval.fit(train_data)\n",
        "best_model = cv_model.bestModel\n",
        "cv_predictions = best_model.transform(test_data)\n",
        "cv_accuracy = evaluator.evaluate(cv_predictions)\n",
        "print(f\"Best Model Accuracy: {cv_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byc6mPlkf4HM",
        "outputId": "4ce72f7b-d248-4dab-f71e-40012cf8b075"
      },
      "id": "Byc6mPlkf4HM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GHqodw4wf8md"
      },
      "id": "GHqodw4wf8md",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}