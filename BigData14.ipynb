{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJBeDQLNwfjp",
        "outputId": "9faf57a9-f819-4f7a-954b-f114f62a7fc5"
      },
      "id": "aJBeDQLNwfjp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ae225b",
      "metadata": {
        "id": "d9ae225b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78c81b2-c472-40b8-bc38-2f4adf8e5944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b266267",
      "metadata": {
        "id": "0b266267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3c31e4-934a-44d4-ea52-5dbbf3830846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionExample\").getOrCreate()\n",
        "\n",
        "# Example dataset\n",
        "data = [\n",
        "    (1, Vectors.dense([2.0, 3.0]), 0),\n",
        "    (2, Vectors.dense([1.0, 5.0]), 1),\n",
        "    (3, Vectors.dense([2.5, 4.5]), 1),\n",
        "    (4, Vectors.dense([3.0, 6.0]), 0)\n",
        "]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n",
        "model = lr.fit(df)\n",
        "\n",
        "# Display coefficients and summary\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9066e04",
      "metadata": {
        "id": "b9066e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b78d3e6-77c8-4303-f586-9c57c7c3a426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([12.5, 12.5]), array([3., 3.])]\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"KMeansClusteringExample\").getOrCreate()\n",
        "\n",
        "# Example dataset with DenseVector\n",
        "data = [\n",
        "    (1, Vectors.dense([1.0, 1.0])),\n",
        "    (2, Vectors.dense([5.0, 5.0])),\n",
        "    (3, Vectors.dense([10.0, 10.0])),\n",
        "    (4, Vectors.dense([15.0, 15.0]))\n",
        "]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='Features', k=2)\n",
        "model = kmeans.fit(df)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Homework\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Apple 2009-2024\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "data = spark.read.csv(\"Apple_Cleaned_2009_2024.csv\", header=True, inferSchema=True)\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEXXWZoPzA99",
        "outputId": "32c925cf-20d8-49ea-a927-a00b19e660d2"
      },
      "id": "UEXXWZoPzA99",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------------+------------------+-----------------------+--------------------+---------------------+----+------------------+----------------+-----------------------+-----------------------+-------------------------+----------------------------+------------+--------+---------+----------+----------------------------+-----------------------------+----------------------------------+\n",
            "|year|EBITDA (millions)|Revenue (millions)|Gross Profit (millions)|Op Income (millions)|Net Income (millions)| EPS|Shares Outstanding|Year Close Price|Total Assets (millions)|Cash on Hand (millions)|Long Term Debt (millions)|Total Liabilities (millions)|Gross Margin|PE ratio|Employees|Is Outlier|Normalized EBITDA (millions)|Normalized Revenue (millions)|Normalized Gross Profit (millions)|\n",
            "+----+-----------------+------------------+-----------------------+--------------------+---------------------+----+------------------+----------------+-----------------------+-----------------------+-------------------------+----------------------------+------------+--------+---------+----------+----------------------------+-----------------------------+----------------------------------+\n",
            "|2024|           134661|            391035|                 180683|              123216|                93736|6.08|             15408|          243.04|                 364980|                  65171|                    85750|                      308030|      46.21%|   39.97|   164000|     false|          0.9999999999999999|           0.9906295262404567|                               1.0|\n",
            "|2023|           125820|            383285|                 169148|              114301|                96995|6.13|             15813|        191.5919|                 352583|                  61555|                    95281|                      290437|      45.03%|   29.84|   161000|     false|          0.9276436936826339|           0.9685763310881759|                 0.929432708719511|\n",
            "|2022|           130541|            394328|                 170782|              119437|                99803|6.11|             16326|        128.5816|                 352755|                  48304|                    98959|                      302083|      43.06%|   21.83|   164000|     false|          0.9662811919434965|                          1.0|                0.9394289769425123|\n",
            "|2021|           120233|            365817|                 152836|              108949|                94680|5.61|             16865|        174.7132|                 351002|                  62639|                   109106|                      287912|      43.02%|   28.93|   154000|     false|          0.8819186983885355|           0.9188698520017187|                 0.829641321171411|\n",
            "|2020|            77344|            274515|                 104956|               66288|                57411|3.28|             17528|        129.7556|                 323888|                  90943|                    98667|                      258549|      38.78%|   35.14|   147000|     false|          0.5309075433556761|           0.6590632940928739|                0.5367274151020733|\n",
            "+----+-----------------+------------------+-----------------------+--------------------+---------------------+----+------------------+----------------+-----------------------+-----------------------+-------------------------+----------------------------+------------+--------+---------+----------+----------------------------+-----------------------------+----------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Apple 2009-2024\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "data = spark.read.csv(\"Apple_Cleaned_2009_2024.csv\", header=True, inferSchema=True)\n",
        "\n",
        "data.show(5)\n",
        "\n",
        "data = data.filter(data['Is Outlier'] == False)\n",
        "\n",
        "# Mengonversi kolom 'Is Outlier' dari Boolean ke Integer\n",
        "data = data.withColumn(\"Is Outlier\", data[\"Is Outlier\"].cast(\"integer\"))\n",
        "\n",
        "# Menyiapkan fitur dan label untuk model klasifikasi\n",
        "# Misalnya, kita akan memprediksi 'Is Outlier' (0 jika bukan outlier, 1 jika outlier)\n",
        "indexer = StringIndexer(inputCol=\"Is Outlier\", outputCol=\"label\")\n",
        "\n",
        "feature_columns = [\n",
        "    'EBITDA (millions)', 'Revenue (millions)', 'Gross Profit (millions)',\n",
        "    'Op Income (millions)', 'Net Income (millions)', 'EPS',\n",
        "    'Shares Outstanding', 'Total Assets (millions)',\n",
        "    'Cash on Hand (millions)', 'Long Term Debt (millions)',\n",
        "    'Total Liabilities (millions)', 'PE ratio', 'Employees'\n",
        "]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
        "\n",
        "# Membangun pipeline\n",
        "pipeline = Pipeline(stages=[indexer, assembler])\n",
        "model_data = pipeline.fit(data).transform(data)\n",
        "model_data.select(\"features\", \"label\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4-v6Qz01_Da",
        "outputId": "7f720cb3-5e29-4e73-efd0-cf09923d7f5a"
      },
      "id": "Q4-v6Qz01_Da",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------------+------------------+-----------------------+--------------------+---------------------+----+------------------+----------------+-----------------------+-----------------------+-------------------------+----------------------------+------------+--------+---------+----------+----------------------------+-----------------------------+----------------------------------+\n",
            "|year|EBITDA (millions)|Revenue (millions)|Gross Profit (millions)|Op Income (millions)|Net Income (millions)| EPS|Shares Outstanding|Year Close Price|Total Assets (millions)|Cash on Hand (millions)|Long Term Debt (millions)|Total Liabilities (millions)|Gross Margin|PE ratio|Employees|Is Outlier|Normalized EBITDA (millions)|Normalized Revenue (millions)|Normalized Gross Profit (millions)|\n",
            "+----+-----------------+------------------+-----------------------+--------------------+---------------------+----+------------------+----------------+-----------------------+-----------------------+-------------------------+----------------------------+------------+--------+---------+----------+----------------------------+-----------------------------+----------------------------------+\n",
            "|2024|           134661|            391035|                 180683|              123216|                93736|6.08|             15408|          243.04|                 364980|                  65171|                    85750|                      308030|      46.21%|   39.97|   164000|     false|          0.9999999999999999|           0.9906295262404567|                               1.0|\n",
            "|2023|           125820|            383285|                 169148|              114301|                96995|6.13|             15813|        191.5919|                 352583|                  61555|                    95281|                      290437|      45.03%|   29.84|   161000|     false|          0.9276436936826339|           0.9685763310881759|                 0.929432708719511|\n",
            "|2022|           130541|            394328|                 170782|              119437|                99803|6.11|             16326|        128.5816|                 352755|                  48304|                    98959|                      302083|      43.06%|   21.83|   164000|     false|          0.9662811919434965|                          1.0|                0.9394289769425123|\n",
            "|2021|           120233|            365817|                 152836|              108949|                94680|5.61|             16865|        174.7132|                 351002|                  62639|                   109106|                      287912|      43.02%|   28.93|   154000|     false|          0.8819186983885355|           0.9188698520017187|                 0.829641321171411|\n",
            "|2020|            77344|            274515|                 104956|               66288|                57411|3.28|             17528|        129.7556|                 323888|                  90943|                    98667|                      258549|      38.78%|   35.14|   147000|     false|          0.5309075433556761|           0.6590632940928739|                0.5367274151020733|\n",
            "+----+-----------------+------------------+-----------------------+--------------------+---------------------+----+------------------+----------------+-----------------------+-----------------------+-------------------------+----------------------------+------------+--------+---------+----------+----------------------------+-----------------------------+----------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|[134661.0,391035....|  0.0|\n",
            "|[125820.0,383285....|  0.0|\n",
            "|[130541.0,394328....|  0.0|\n",
            "|[120233.0,365817....|  0.0|\n",
            "|[77344.0,274515.0...|  0.0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "train_data, test_data = model_data.randomSplit([0.8, 0.2], seed=1234)\n",
        "dt_classifier = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
        "dt_model = dt_classifier.fit(train_data)\n",
        "\n",
        "# Melakukan prediksi\n",
        "predictions = dt_model.transform(test_data)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "UMC4yIfqdnqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e9f4f4-e68d-4e41-9050-65820f588150"
      },
      "id": "UMC4yIfqdnqr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Membangun grid untuk hyperparameter tuning\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(dt_classifier.maxDepth, [2, 5, 10]) \\\n",
        "    .addGrid(dt_classifier.minInstancesPerNode, [1, 2, 5]) \\\n",
        "    .build()\n",
        "\n",
        "# CrossValidator\n",
        "crossval = CrossValidator(estimator=dt_classifier,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)\n",
        "\n",
        "cv_model = crossval.fit(train_data)\n",
        "best_model = cv_model.bestModel\n",
        "cv_predictions = best_model.transform(test_data)\n",
        "cv_accuracy = evaluator.evaluate(cv_predictions)\n",
        "print(f\"Best Model Accuracy: {cv_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byc6mPlkf4HM",
        "outputId": "4ce72f7b-d248-4dab-f71e-40012cf8b075"
      },
      "id": "Byc6mPlkf4HM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Accuracy: 1.00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}